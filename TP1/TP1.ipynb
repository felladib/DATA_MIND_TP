{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About DATASET**\n",
    "\n",
    "This dataset contains accelerometer and gyroscope readings gathered from participants\n",
    "performing a variety of exercises. It includes sensor data from the accelerometer (x, y, z\n",
    "axes) and gyroscope (x, y, z axes) across different exercise types and intensities. This data\n",
    "is well-suited for analyzing movement patterns, developing activity recognition models,\n",
    "and training machine learning algorithms for fitness and health monitoring.\n",
    "* ep (ms): Timestamp in milliseconds, representing the exact recording time.\n",
    "* Acc_x: X-axis acceleration value from the fitness tracker.\n",
    "* Acc_y: Y-axis acceleration value from the fitness tracker.\n",
    "* Acc_z: Z-axis acceleration value from the fitness tracker.\n",
    "* Gyro_x: X-axis rotational velocity (gyroscope) reading.\n",
    "* Gyro_y: Y-axis rotational velocity (gyroscope) reading.\n",
    "* Gyro_z: Z-axis rotational velocity (gyroscope) reading.\n",
    "* ID: Identifier for the individual performing the exercise.\n",
    "* Exercise: Type of exercise or movement (e.g., bench press, overhead press).\n",
    "* Category: Intensity of the exercise (e.g., heavy, medium).\n",
    "* Set: Set number or batch identifier for the recorded session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*import dependencies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*creation d'un objet pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = pd.Series([1, 4, -1, np.nan, .5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1- Write a function to load the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(chemin):\n",
    "   try:\n",
    "      data = pd.read_csv(chemin , sep=';' )\n",
    "      return data\n",
    "   except Exception as e:\n",
    "      print(f\"Une erreur s'est produite : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_data = '..//DATA//DatasetExos.csv'\n",
    "data = load_data(chemin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep (ms)</th>\n",
       "      <th>Acc_x</th>\n",
       "      <th>Acc_y</th>\n",
       "      <th>Acc_z</th>\n",
       "      <th>Gyro_x</th>\n",
       "      <th>Gyro_y</th>\n",
       "      <th>Gyro_z</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-11 15:08:05.200</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-2.094.366.723</td>\n",
       "      <td>257.720.316</td>\n",
       "      <td>0.9388000000000002</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-11 15:08:05.400</td>\n",
       "      <td>-0.0014999999999999996</td>\n",
       "      <td>0.9704999999999999</td>\n",
       "      <td>-0.07949999999999999</td>\n",
       "      <td>-16.826</td>\n",
       "      <td>-0.8904</td>\n",
       "      <td>21.708</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-11 15:08:05.600</td>\n",
       "      <td>0.0013333333333333333</td>\n",
       "      <td>0.9716666666666667</td>\n",
       "      <td>-0.06433333333333334</td>\n",
       "      <td>526.942.212</td>\n",
       "      <td>-0.2559999999999999</td>\n",
       "      <td>-14.146</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-11 15:08:05.800</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-0.0735</td>\n",
       "      <td>8.061</td>\n",
       "      <td>-45.244</td>\n",
       "      <td>-2.073</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11 15:08:06.000</td>\n",
       "      <td>-0.027999999999999997</td>\n",
       "      <td>0.9576666666666666</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>2.439</td>\n",
       "      <td>-15.486</td>\n",
       "      <td>-36.098</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-11 15:08:06.200</td>\n",
       "      <td>-0.026000000000000002</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.4634000000000002</td>\n",
       "      <td>52.194</td>\n",
       "      <td>-64.636</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-11 15:08:06.400</td>\n",
       "      <td>-0.048666666666666664</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-0.14533333333333334</td>\n",
       "      <td>21.695</td>\n",
       "      <td>81.708</td>\n",
       "      <td>1.582.030.845</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-11 15:08:06.600</td>\n",
       "      <td>-0.16999999999999998</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>175.246</td>\n",
       "      <td>15.976</td>\n",
       "      <td>-175.854</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-11 15:08:06.800</td>\n",
       "      <td>-0.22266666666666668</td>\n",
       "      <td>0.907</td>\n",
       "      <td>-0.20433333333333334</td>\n",
       "      <td>-72.318</td>\n",
       "      <td>-13.536</td>\n",
       "      <td>-0.40260000000000007</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-11 15:08:07.000</td>\n",
       "      <td>-0.20450000000000002</td>\n",
       "      <td>0.9299999999999999</td>\n",
       "      <td>-0.14900000000000002</td>\n",
       "      <td>-28.683</td>\n",
       "      <td>-335.699.969</td>\n",
       "      <td>205.732</td>\n",
       "      <td>B</td>\n",
       "      <td>bench</td>\n",
       "      <td>heavy</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ep (ms)                   Acc_x               Acc_y  \\\n",
       "0  2019-01-11 15:08:05.200                  0.0135               0.977   \n",
       "1  2019-01-11 15:08:05.400  -0.0014999999999999996  0.9704999999999999   \n",
       "2  2019-01-11 15:08:05.600   0.0013333333333333333  0.9716666666666667   \n",
       "3  2019-01-11 15:08:05.800                  -0.024               0.957   \n",
       "4  2019-01-11 15:08:06.000   -0.027999999999999997  0.9576666666666666   \n",
       "5  2019-01-11 15:08:06.200   -0.026000000000000002               0.965   \n",
       "6  2019-01-11 15:08:06.400   -0.048666666666666664                0.79   \n",
       "7  2019-01-11 15:08:06.600    -0.16999999999999998              0.8995   \n",
       "8  2019-01-11 15:08:06.800    -0.22266666666666668               0.907   \n",
       "9  2019-01-11 15:08:07.000    -0.20450000000000002  0.9299999999999999   \n",
       "\n",
       "                  Acc_z              Gyro_x               Gyro_y  \\\n",
       "0                -0.071      -2.094.366.723          257.720.316   \n",
       "1  -0.07949999999999999             -16.826              -0.8904   \n",
       "2  -0.06433333333333334         526.942.212  -0.2559999999999999   \n",
       "3               -0.0735               8.061              -45.244   \n",
       "4                -0.115               2.439              -15.486   \n",
       "5                -0.118  0.4634000000000002               52.194   \n",
       "6  -0.14533333333333334              21.695               81.708   \n",
       "7                 -0.25             175.246               15.976   \n",
       "8  -0.20433333333333334             -72.318              -13.536   \n",
       "9  -0.14900000000000002             -28.683         -335.699.969   \n",
       "\n",
       "                 Gyro_z ID  Label Category   Set  \n",
       "0    0.9388000000000002  B  bench    heavy  30.0  \n",
       "1                21.708  B  bench    heavy  30.0  \n",
       "2               -14.146  B  bench    heavy  30.0  \n",
       "3                -2.073  B  bench    heavy  30.0  \n",
       "4               -36.098  B  bench    heavy  30.0  \n",
       "5               -64.636  B  bench    heavy  30.0  \n",
       "6         1.582.030.845  B  bench    heavy  30.0  \n",
       "7              -175.854  B  bench    heavy  30.0  \n",
       "8  -0.40260000000000007  B  bench    heavy  30.0  \n",
       "9               205.732  B  bench    heavy  30.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2- Write a function to display basic information about the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_info(data):\n",
    "    print(\"data information : \\n \" , data.info())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def display_dataset_info(data):\n",
    "    # number of rows and columns)\n",
    "    print(\"Dataset shape:\", data.shape)\n",
    "    \n",
    "    # noms des colonnes\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(data.columns.tolist())\n",
    "    \n",
    "    # type de données\n",
    "    print(\"\\nData types:\")\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    # Display summary statistics for numerical columns\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(data.describe())\n",
    "    \n",
    "    # Display missing values for each column\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(data.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9009, 11)\n",
      "\n",
      "Column names:\n",
      "['ep (ms)', 'Acc_x', 'Acc_y', 'Acc_z', 'Gyro_x', 'Gyro_y', 'Gyro_z', 'ID', 'Label', 'Category', 'Set']\n",
      "\n",
      "Data types:\n",
      "ep (ms)      object\n",
      "Acc_x        object\n",
      "Acc_y        object\n",
      "Acc_z        object\n",
      "Gyro_x       object\n",
      "Gyro_y       object\n",
      "Gyro_z       object\n",
      "ID           object\n",
      "Label        object\n",
      "Category     object\n",
      "Set         float64\n",
      "dtype: object\n",
      "\n",
      "Summary statistics:\n",
      "               Set\n",
      "count  9003.000000\n",
      "mean     46.105520\n",
      "std      34.108085\n",
      "min     -10.000000\n",
      "25%      23.000000\n",
      "50%      47.000000\n",
      "75%      70.000000\n",
      "max    2000.000000\n",
      "\n",
      "Missing values:\n",
      "ep (ms)     11\n",
      "Acc_x        3\n",
      "Acc_y        2\n",
      "Acc_z        3\n",
      "Gyro_x       1\n",
      "Gyro_y       0\n",
      "Gyro_z       1\n",
      "ID           2\n",
      "Label        0\n",
      "Category     4\n",
      "Set          6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "display_dataset_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3- Write a function to calculate the central tendencies of an attribute.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *fonction median*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(data):\n",
    "    # Supprimer les NaN\n",
    "    cleaned_data = data.dropna().sort_values()\n",
    "    n = len(cleaned_data)\n",
    "    \n",
    "    if n == 0:\n",
    "        return None  # Si la liste est vide après avoir supprimé les NaN\n",
    "    \n",
    "    if n % 2 == 0:\n",
    "        Q2 = (cleaned_data.iloc[n // 2 - 1] + cleaned_data.iloc[n // 2]) / 2\n",
    "    else:\n",
    "        Q2 = cleaned_data.iloc[n // 2]\n",
    "    return Q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median(pd.to_numeric(data['Acc_x'], errors='coerce'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *focntion mood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(data):\n",
    "     # Supprimer les NaN\n",
    "    cleaned_data = data.dropna()\n",
    "    if len(cleaned_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # compter le nombre d'occurrences de chaque valeur dans data.\n",
    "    occurence = cleaned_data.value_counts()\n",
    "    # Cette valeur représente le nombre d'occurrences maximum trouvé dans data\n",
    "    max_count = occurence.iloc[0]\n",
    "    # Cette ligne filtre la Series occurence pour ne garder que les éléments dont la valeur (le nombre d’occurrences) est égale à max_count. Ensuite, elle utilise .index pour récupérer les valeurs qui correspondent à ces occurrences maximales.\n",
    "    mode_list = occurence[occurence == max_count].index.tolist()\n",
    "    \n",
    "    return mode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.12', '-0.125']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode(data['Acc_z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *fonction quartiles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartiles(data):\n",
    "    # Supprimer les NaN\n",
    "    cleaned_data = data.dropna().sort_values()\n",
    "  \n",
    "    Q0 = cleaned_data.min()\n",
    "    Q4 = cleaned_data.max()\n",
    "    Q2 = median(cleaned_data)\n",
    "    Q1 = cleaned_data.iloc[int(len(cleaned_data) * 0.25)]\n",
    "    Q3 = cleaned_data.iloc[int(len(cleaned_data) * 0.75)]\n",
    "\n",
    "    return Q0 , Q1 , Q2 , Q3 , Q4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8380000000000001, -0.1115, 0.016, 0.1176666666666666, 10.255)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quartiles(pd.to_numeric(data['Acc_x'], errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_central_tendencies(data, column_name):\n",
    "    if column_name not in data.columns:\n",
    "        print(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # convert to numeric \n",
    "    data[column_name] = pd.to_numeric(data[column_name], errors='coerce') #s'il y'a de valeur Nan\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean_value = data[column_name].mean()\n",
    "    \n",
    "    # Calculate median\n",
    "    median_value = median(data[column_name])\n",
    "    \n",
    "    # Calculate mode\n",
    "    mode_value = mode(data[column_name])\n",
    "\n",
    "    # Handle the case of mode\n",
    "    if len(mode_value) > 1:\n",
    "        mode_value = mode_value.tolist()  # Convert to list if multiple modes\n",
    "    else:\n",
    "        mode_value = mode_value[0]  # Take the single mode value\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Central tendencies for '{column_name}':\")\n",
    "    print(f\"Mean: {mean_value}\")\n",
    "    print(f\"Median: {median_value}\")\n",
    "    print(f\"Mode: {mode_value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central tendencies for 'Acc_x':\n",
      "Mean: 0.04590467712621936\n",
      "Median: 0.016\n",
      "Mode: 0.078\n"
     ]
    }
   ],
   "source": [
    "calculate_central_tendencies(data, 'Acc_x')  # Replace 'Acc_x' with the column you want to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4- Write a function to calculate the quartiles (Q0, Q1, Q2, Q3, Q4) of an attribute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric columns (as defined earlier)\n",
    "# for column in ['Acc_x', 'Acc_y', 'Acc_z', 'Gyro_x', 'Gyro_y', 'Gyro_z']:\n",
    "#     data[column] = pd.to_numeric(data[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quartiles(data, column_name):\n",
    "    if column_name not in data.columns:\n",
    "        print(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "        return\n",
    "\n",
    "    Q0, Q1, Q2, Q3, Q4 = quartiles(data[column_name])\n",
    "    print(f\"Quartiles for '{column_name}':\")\n",
    "    print(f\"Q0 (Min): {Q0}\")\n",
    "    print(f\"Q1 (25th percentile): {Q1}\")\n",
    "    print(f\"Q2 (Median): {Q2}\")\n",
    "    print(f\"Q3 (75th percentile): {Q3}\")\n",
    "    print(f\"Q4 (Max): {Q4}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartiles for 'Acc_x':\n",
      "Q0 (Min): -0.8380000000000001\n",
      "Q1 (25th percentile): -0.1115\n",
      "Q2 (Median): 0.016\n",
      "Q3 (75th percentile): 0.1176666666666666\n",
      "Q4 (Max): 10.255\n"
     ]
    }
   ],
   "source": [
    "calculate_quartiles(data, 'Acc_x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5- Write a function to display the number and percentage of missing values for an attribute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_missing_values(data, column_name):\n",
    "    if column_name not in data.columns:\n",
    "        print(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "        return\n",
    "\n",
    "    missing_count = data[column_name].isnull().sum()\n",
    "    total_count = data[column_name].shape[0]\n",
    "    missing_percentage = (missing_count / total_count) * 100\n",
    "    \n",
    "    print(f\"Missing values in '{column_name}':\")\n",
    "    print(f\"Count: {missing_count}\")\n",
    "    print(f\"Percentage: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'Acc_x':\n",
      "Count: 22\n",
      "Percentage: 0.24%\n"
     ]
    }
   ],
   "source": [
    "display_missing_values(data, 'Acc_x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*6- Write a function to display the number of unique values for an attribute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_unique_values(data, column_name):\n",
    "    \n",
    "    if column_name not in data.columns:\n",
    "        print(f\"Column '{column_name}' does not exist in the dataset.\")\n",
    "        return\n",
    "    print(type(data[column_name][0]))\n",
    "    unique_count = data[column_name].nunique()\n",
    "    print(f\"Unique values in '{column_name}': {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Unique values in 'ID': 6\n"
     ]
    }
   ],
   "source": [
    "display_unique_values(data, 'ID')  # Change 'ID' to any column you want to check unique values for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
